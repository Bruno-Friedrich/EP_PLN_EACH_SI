{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcca369f",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3112fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc7679a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "001665b0",
   "metadata": {},
   "source": [
    "# CONFIGURA√á√ïES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "11b7c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_FOLDER_TRAIN = \"treino\"\n",
    "\n",
    "FILES = [\n",
    "    \"train_literal_dinamico.csv\",\n",
    "    \"train_complexo_simples.csv\",\n",
    "    \"train_arcaico_moderno.csv\",\n",
    "]\n",
    "\n",
    "preprocess_params = {\n",
    "    \"lowercase\": True,\n",
    "    \"normalize_unicode\": False,\n",
    "    \"remove_extra_whitespace\": True,\n",
    "    \"remove_punct\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4a49aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√£o dos Pipelines e Grades de Hiperpar√¢metros para Grid Search\n",
    "param_grids = {\n",
    "    'Naive Bayes': {\n",
    "        'pipeline': Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer()),\n",
    "            ('model', MultinomialNB())\n",
    "        ]),\n",
    "        'params': {\n",
    "            'vectorizer__max_features': [3000, 5000, 10000],\n",
    "            'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "            'vectorizer__min_df': [2, 5],\n",
    "            'vectorizer__max_df': [0.9, 0.95],\n",
    "            'model__alpha': [0.1, 0.5, 1.0, 2.0]\n",
    "        }\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'pipeline': Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer()),\n",
    "            ('model', LogisticRegression(max_iter=1000, random_state=42))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'vectorizer__max_features': [3000, 5000, 10000],\n",
    "            'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "            'vectorizer__min_df': [2, 5],\n",
    "            'vectorizer__max_df': [0.9, 0.95],\n",
    "            'model__C': [0.1, 1.0, 10.0],\n",
    "            'model__solver': ['lbfgs', 'liblinear'],\n",
    "            'model__class_weight': ['balanced', None]\n",
    "        }\n",
    "    },\n",
    "    'SVM (LinearSVC)': {\n",
    "        'pipeline': Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer()),\n",
    "            ('model', LinearSVC(dual=False, random_state=42))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'vectorizer__max_features': [3000, 5000, 10000],\n",
    "            'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "            'vectorizer__min_df': [2, 5],\n",
    "            'vectorizer__max_df': [0.9, 0.95],\n",
    "            'model__C': [0.1, 1.0, 10.0],\n",
    "            'model__max_iter': [1000, 2000]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5515f",
   "metadata": {},
   "source": [
    "# AN√ÅLISE DE BALANCEAMENTO DOS DATASETS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6f36e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_balanceamento(file_name):\n",
    "    \"\"\"Fun√ß√£o para analisar o balanceamento de um dataset\"\"\"\n",
    "    path = os.path.join(BASE_FOLDER_TRAIN, file_name)\n",
    "    df = pd.read_csv(path, sep=\";\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"AN√ÅLISE ESTAT√çSTICA - {file_name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Informa√ß√µes b√°sicas\n",
    "    print(f\"\\nüìä INFORMA√á√ïES GERAIS:\")\n",
    "    print(f\"   ‚Ä¢ Total de linhas: {len(df):,}\")\n",
    "    print(f\"   ‚Ä¢ Total de colunas: {len(df.columns)}\")\n",
    "    print(f\"   ‚Ä¢ Colunas: {list(df.columns)}\")\n",
    "    \n",
    "    # Verificar valores nulos\n",
    "    print(f\"\\nüîç VALORES NULOS:\")\n",
    "    print(f\"   ‚Ä¢ Coluna 'text': {df['text'].isna().sum()}\")\n",
    "    print(f\"   ‚Ä¢ Coluna 'style': {df['style'].isna().sum()}\")\n",
    "    \n",
    "    # Distribui√ß√£o das classes\n",
    "    print(f\"\\nüìà DISTRIBUI√á√ÉO DAS CLASSES:\")\n",
    "    contagem_classes = df['style'].value_counts()\n",
    "    print(contagem_classes)\n",
    "    \n",
    "    print(f\"\\nüìä PORCENTAGEM POR CLASSE:\")\n",
    "    porcentagem_classes = df['style'].value_counts(normalize=True) * 100\n",
    "    for classe, perc in porcentagem_classes.items():\n",
    "        count = contagem_classes[classe]\n",
    "        print(f\"   ‚Ä¢ {classe}: {count:,} ({perc:.2f}%)\")\n",
    "    \n",
    "    # Verificar balanceamento\n",
    "    print(f\"\\n‚öñÔ∏è BALANCEAMENTO:\")\n",
    "    razao = contagem_classes.max() / contagem_classes.min()\n",
    "    print(f\"   ‚Ä¢ Raz√£o maior/menor classe: {razao:.2f}x\")\n",
    "    if razao < 1.5:\n",
    "        print(f\"   ‚Ä¢ Status: ‚úÖ Dataset bem balanceado\")\n",
    "    elif razao < 3:\n",
    "        print(f\"   ‚Ä¢ Status: ‚ö†Ô∏è Dataset moderadamente desbalanceado\")\n",
    "    else:\n",
    "        print(f\"   ‚Ä¢ Status: ‚ùå Dataset desbalanceado\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print()\n",
    "    \n",
    "    return df, contagem_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7f6d70c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AN√ÅLISE ESTAT√çSTICA - train_literal_dinamico.csv\n",
      "============================================================\n",
      "\n",
      "üìä INFORMA√á√ïES GERAIS:\n",
      "   ‚Ä¢ Total de linhas: 36,964\n",
      "   ‚Ä¢ Total de colunas: 2\n",
      "   ‚Ä¢ Colunas: ['text', 'style']\n",
      "\n",
      "üîç VALORES NULOS:\n",
      "   ‚Ä¢ Coluna 'text': 0\n",
      "   ‚Ä¢ Coluna 'style': 0\n",
      "\n",
      "üìà DISTRIBUI√á√ÉO DAS CLASSES:\n",
      "style\n",
      "literal     18482\n",
      "dinamico    18482\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä PORCENTAGEM POR CLASSE:\n",
      "   ‚Ä¢ literal: 18,482 (50.00%)\n",
      "   ‚Ä¢ dinamico: 18,482 (50.00%)\n",
      "\n",
      "‚öñÔ∏è BALANCEAMENTO:\n",
      "   ‚Ä¢ Raz√£o maior/menor classe: 1.00x\n",
      "   ‚Ä¢ Status: ‚úÖ Dataset bem balanceado\n",
      "\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "AN√ÅLISE ESTAT√çSTICA - train_complexo_simples.csv\n",
      "============================================================\n",
      "\n",
      "üìä INFORMA√á√ïES GERAIS:\n",
      "   ‚Ä¢ Total de linhas: 33,422\n",
      "   ‚Ä¢ Total de colunas: 2\n",
      "   ‚Ä¢ Colunas: ['text', 'style']\n",
      "\n",
      "üîç VALORES NULOS:\n",
      "   ‚Ä¢ Coluna 'text': 1\n",
      "   ‚Ä¢ Coluna 'style': 0\n",
      "\n",
      "üìà DISTRIBUI√á√ÉO DAS CLASSES:\n",
      "style\n",
      "complexo    16711\n",
      "simples     16711\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä PORCENTAGEM POR CLASSE:\n",
      "   ‚Ä¢ complexo: 16,711 (50.00%)\n",
      "   ‚Ä¢ simples: 16,711 (50.00%)\n",
      "\n",
      "‚öñÔ∏è BALANCEAMENTO:\n",
      "   ‚Ä¢ Raz√£o maior/menor classe: 1.00x\n",
      "   ‚Ä¢ Status: ‚úÖ Dataset bem balanceado\n",
      "\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "AN√ÅLISE ESTAT√çSTICA - train_arcaico_moderno.csv\n",
      "============================================================\n",
      "\n",
      "üìä INFORMA√á√ïES GERAIS:\n",
      "   ‚Ä¢ Total de linhas: 36,884\n",
      "   ‚Ä¢ Total de colunas: 2\n",
      "   ‚Ä¢ Colunas: ['text', 'style']\n",
      "\n",
      "üîç VALORES NULOS:\n",
      "   ‚Ä¢ Coluna 'text': 0\n",
      "   ‚Ä¢ Coluna 'style': 0\n",
      "\n",
      "üìà DISTRIBUI√á√ÉO DAS CLASSES:\n",
      "style\n",
      "arcaico    18442\n",
      "moderno    18442\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä PORCENTAGEM POR CLASSE:\n",
      "   ‚Ä¢ arcaico: 18,442 (50.00%)\n",
      "   ‚Ä¢ moderno: 18,442 (50.00%)\n",
      "\n",
      "‚öñÔ∏è BALANCEAMENTO:\n",
      "   ‚Ä¢ Raz√£o maior/menor classe: 1.00x\n",
      "   ‚Ä¢ Status: ‚úÖ Dataset bem balanceado\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analisar todos os datasets\n",
    "resultados_analise = {}\n",
    "\n",
    "for file_name in FILES:\n",
    "    df, contagem = analisar_balanceamento(file_name)\n",
    "    resultados_analise[file_name] = {\n",
    "        'dataframe': df,\n",
    "        'contagem_classes': contagem\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "22520141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RESUMO COMPARATIVO - TODOS OS DATASETS\n",
      "================================================================================\n",
      "\n",
      "         Dataset  Total Linhas Classe 1  Count 1 Classe 2  Count 2 Raz√£o       Status\n",
      "literal_dinamico         36964  literal    18482 dinamico    18482 1.00x ‚úÖ Balanceado\n",
      "complexo_simples         33422 complexo    16711  simples    16711 1.00x ‚úÖ Balanceado\n",
      " arcaico_moderno         36884  arcaico    18442  moderno    18442 1.00x ‚úÖ Balanceado\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Criar tabela resumo comparativa\n",
    "print(\"=\"*80)\n",
    "print(\"RESUMO COMPARATIVO - TODOS OS DATASETS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "resumo_data = []\n",
    "for file_name, resultado in resultados_analise.items():\n",
    "    df = resultado['dataframe']\n",
    "    contagem = resultado['contagem_classes']\n",
    "    razao = contagem.max() / contagem.min()\n",
    "    \n",
    "    resumo_data.append({\n",
    "        'Dataset': file_name.replace('train_', '').replace('.csv', ''),\n",
    "        'Total Linhas': len(df),\n",
    "        'Classe 1': contagem.index[0],\n",
    "        'Count 1': contagem.values[0],\n",
    "        'Classe 2': contagem.index[1],\n",
    "        'Count 2': contagem.values[1],\n",
    "        'Raz√£o': f\"{razao:.2f}x\",\n",
    "        'Status': '‚úÖ Balanceado' if razao < 1.5 else '‚ö†Ô∏è Moderado' if razao < 3 else '‚ùå Desbalanceado'\n",
    "    })\n",
    "\n",
    "df_resumo = pd.DataFrame(resumo_data)\n",
    "print(df_resumo.to_string(index=False))\n",
    "print()\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2c9bcd",
   "metadata": {},
   "source": [
    "# PR√â-PROCESSAMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "93b8d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_operations(text, params):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    if params.get(\"normalize_unicode\", True):\n",
    "        text = unicodedata.normalize(\"NFKC\", text)\n",
    "    if params.get(\"lowercase\", True):\n",
    "        text = text.lower()\n",
    "    if params.get(\"remove_punct\", False):\n",
    "        text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "    if params.get(\"remove_extra_whitespace\", True):\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def preprocess_data(path):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Aviso: {path} n√£o encontrado.\")\n",
    "        return None\n",
    "\n",
    "    df = pd.read_csv(path, sep=\";\")\n",
    "    col_text, col_label = \"text\", \"style\"\n",
    "\n",
    "    df = df[[col_text, col_label]].dropna()\n",
    "    df = shuffle(df, random_state=10).reset_index(drop=True)\n",
    "\n",
    "    df[\"text_preproc\"] = df[col_text].apply(lambda x: preprocess_operations(x, preprocess_params))\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df[col_label])\n",
    "    X = df[\"text_preproc\"].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.15, stratify=y, random_state=10\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "69a3aeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando: train_literal_dinamico.csv\n",
      "\n",
      "Processando: train_complexo_simples.csv\n",
      "\n",
      "Processando: train_arcaico_moderno.csv\n"
     ]
    }
   ],
   "source": [
    "datasets = {}\n",
    "\n",
    "for file_name in FILES:\n",
    "    path = os.path.join(BASE_FOLDER_TRAIN, file_name)\n",
    "    print(f\"\\nProcessando: {file_name}\")\n",
    "    result = preprocess_data(path) \n",
    "\n",
    "    if result is not None:\n",
    "        X_train, X_test, y_train, y_test = result\n",
    "        datasets[file_name] = {\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\": y_train,\n",
    "            \"y_test\": y_test\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2991cd",
   "metadata": {},
   "source": [
    "# DATASET 1: ARCAICO vs MODERNO\n",
    "\n",
    "Classifica√ß√£o de textos entre estilo **arcaico** e **moderno**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c9b11e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados - train_arcaico_moderno.csv\n",
      "   Treino: 31351 textos | Teste: 5533 textos\n"
     ]
    }
   ],
   "source": [
    "# Preparar dados - arcaico_moderno\n",
    "X_train = datasets[\"train_arcaico_moderno.csv\"][\"X_train\"]\n",
    "X_test = datasets[\"train_arcaico_moderno.csv\"][\"X_test\"]\n",
    "y_train = datasets[\"train_arcaico_moderno.csv\"][\"y_train\"]\n",
    "y_test = datasets[\"train_arcaico_moderno.csv\"][\"y_test\"]\n",
    "\n",
    "print(f\"Dados carregados - train_arcaico_moderno.csv\")\n",
    "print(f\"   Treino: {len(X_train)} textos | Teste: {len(X_test)} textos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c41ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GRID SEARCH COM PIPELINE - ARCAICO vs MODERNO (10-FOLD CV)\n",
      "================================================================================\n",
      "Otimizando TF-IDF + Modelos simultaneamente...\n",
      "\n",
      "[Naive Bayes] Executando Grid Search...\n",
      "   Testando 24 combina√ß√µes de TF-IDF...\n",
      "  ‚úì Melhores params TF-IDF: {'max_df': 0.9, 'max_features': 10000, 'min_df': 2, 'ngram_range': (1, 2)}\n",
      "  ‚úì Melhores params Modelo: {'alpha': 0.1}\n",
      "  ‚úì Acuracia (CV): 0.8362\n",
      "\n",
      "[Logistic Regression] Executando Grid Search...\n",
      "   Testando 24 combina√ß√µes de TF-IDF...\n",
      "  ‚úì Melhores params TF-IDF: {'max_df': 0.9, 'max_features': 10000, 'min_df': 5, 'ngram_range': (1, 2)}\n",
      "  ‚úì Melhores params Modelo: {'C': 10.0, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
      "  ‚úì Acuracia (CV): 0.8386\n",
      "\n",
      "[SVM (LinearSVC)] Executando Grid Search...\n",
      "   Testando 24 combina√ß√µes de TF-IDF...\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"GRID SEARCH COM PIPELINE - ARCAICO vs MODERNO (10-FOLD CV)\")\n",
    "print(\"=\"*80)\n",
    "print(\"Otimizando TF-IDF + Modelos simultaneamente...\\n\")\n",
    "\n",
    "# Armazenar melhores pipelines\n",
    "best_models = {}\n",
    "cv_results = {}\n",
    "\n",
    "for name, config in param_grids.items():\n",
    "    print(f\"[{name}] Executando Grid Search...\")\n",
    "    print(f\"   Testando {len(config['params']['vectorizer__max_features']) * len(config['params']['vectorizer__ngram_range']) * len(config['params']['vectorizer__min_df']) * len(config['params']['vectorizer__max_df'])} combina√ß√µes de TF-IDF...\")\n",
    "    \n",
    "    # Grid Search com 10-fold CV\n",
    "    grid_search = GridSearchCV(\n",
    "        config['pipeline'],\n",
    "        config['params'],\n",
    "        cv=10,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Armazenar resultados\n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    \n",
    "    # Separar par√¢metros de TF-IDF e modelo\n",
    "    vectorizer_params = {k.replace('vectorizer__', ''): v \n",
    "                        for k, v in grid_search.best_params_.items() \n",
    "                        if k.startswith('vectorizer__')}\n",
    "    model_params = {k.replace('model__', ''): v \n",
    "                   for k, v in grid_search.best_params_.items() \n",
    "                   if k.startswith('model__')}\n",
    "    \n",
    "    cv_results[name] = {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'vectorizer_params': vectorizer_params,\n",
    "        'model_params': model_params,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'mean': grid_search.best_score_,\n",
    "        'std': grid_search.cv_results_['std_test_score'][grid_search.best_index_]\n",
    "    }\n",
    "    \n",
    "    print(f\"  ‚úì Melhores params TF-IDF: {vectorizer_params}\")\n",
    "    print(f\"  ‚úì Melhores params Modelo: {model_params}\")\n",
    "    print(f\"  ‚úì Acuracia (CV): {grid_search.best_score_:.4f}\\n\")\n",
    "\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd670390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste Final - arcaico_moderno (com melhores params do Grid Search)\n",
    "print(\"\\nTeste Final no Hold-Out - ARCAICO vs MODERNO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_results = {}\n",
    "for name, pipeline in best_models.items():\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    final_results[name] = {'holdout_acc': acc, 'cv_mean': cv_results[name]['mean']}\n",
    "    print(f\"{name:25s}: CV={cv_results[name]['mean']:.4f} | Hold-Out={acc:.4f}\")\n",
    "\n",
    "best_final = max(final_results.items(), key=lambda x: x[1]['holdout_acc'])\n",
    "print(f\"\\nMelhor modelo (Hold-Out): {best_final[0]} - {best_final[1]['holdout_acc']*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f110d7b1",
   "metadata": {},
   "source": [
    "# DATASET 2: COMPLEXO vs SIMPLES\n",
    "\n",
    "Classifica√ß√£o de textos entre estilo **complexo** e **simples**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71362410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vetoriza√ß√£o conclu√≠da - train_complexo_simples.csv\n",
      "   Treino: (28407, 4000) | Teste: (5014, 4000)\n"
     ]
    }
   ],
   "source": [
    "# Preparar dados - complexo_simples\n",
    "X_train_cs = datasets[\"train_complexo_simples.csv\"][\"X_train\"]\n",
    "X_test_cs = datasets[\"train_complexo_simples.csv\"][\"X_test\"]\n",
    "y_train_cs = datasets[\"train_complexo_simples.csv\"][\"y_train\"]\n",
    "y_test_cs = datasets[\"train_complexo_simples.csv\"][\"y_test\"]\n",
    "\n",
    "print(f\"Dados carregados - train_complexo_simples.csv\")\n",
    "print(f\"   Treino: {len(X_train_cs)} textos | Teste: {len(X_test_cs)} textos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fc66bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GRID SEARCH - COMPLEXO vs SIMPLES (10-FOLD CV)\n",
      "================================================================================\n",
      "\n",
      "Otimizando hiperparametros...\n",
      "\n",
      "[Naive Bayes] Executando Grid Search...\n",
      "  ‚úì Melhores params: {'alpha': 0.1}\n",
      "  ‚úì Acuracia (CV): 0.7961\n",
      "\n",
      "[Logistic Regression] Executando Grid Search...\n",
      "  ‚úì Melhores params: {'C': 10.0, 'class_weight': None, 'solver': 'lbfgs'}\n",
      "  ‚úì Acuracia (CV): 0.8238\n",
      "\n",
      "[SVM (LinearSVC)] Executando Grid Search...\n",
      "  ‚úì Melhores params: {'C': 1.0, 'max_iter': 1000}\n",
      "  ‚úì Acuracia (CV): 0.8216\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"GRID SEARCH COM PIPELINE - COMPLEXO vs SIMPLES (10-FOLD CV)\")\n",
    "print(\"=\"*80)\n",
    "print(\"Otimizando TF-IDF + Modelos simultaneamente...\\n\")\n",
    "\n",
    "# Armazenar melhores pipelines\n",
    "best_models_cs = {}\n",
    "cv_results_cs = {}\n",
    "\n",
    "for name, config in param_grids.items():\n",
    "    print(f\"[{name}] Executando Grid Search...\")\n",
    "    print(f\"   Testando {len(config['params']['vectorizer__max_features']) * len(config['params']['vectorizer__ngram_range']) * len(config['params']['vectorizer__min_df']) * len(config['params']['vectorizer__max_df'])} combina√ß√µes de TF-IDF...\")\n",
    "    \n",
    "    # Grid Search com 10-fold CV\n",
    "    grid_search = GridSearchCV(\n",
    "        config['pipeline'],\n",
    "        config['params'],\n",
    "        cv=10,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train_cs, y_train_cs)\n",
    "    \n",
    "    # Armazenar resultados\n",
    "    best_models_cs[name] = grid_search.best_estimator_\n",
    "    \n",
    "    # Separar par√¢metros de TF-IDF e modelo\n",
    "    vectorizer_params = {k.replace('vectorizer__', ''): v \n",
    "                        for k, v in grid_search.best_params_.items() \n",
    "                        if k.startswith('vectorizer__')}\n",
    "    model_params = {k.replace('model__', ''): v \n",
    "                   for k, v in grid_search.best_params_.items() \n",
    "                   if k.startswith('model__')}\n",
    "    \n",
    "    cv_results_cs[name] = {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'vectorizer_params': vectorizer_params,\n",
    "        'model_params': model_params,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'mean': grid_search.best_score_,\n",
    "        'std': grid_search.cv_results_['std_test_score'][grid_search.best_index_]\n",
    "    }\n",
    "    \n",
    "    print(f\"  ‚úì Melhores params TF-IDF: {vectorizer_params}\")\n",
    "    print(f\"  ‚úì Melhores params Modelo: {model_params}\")\n",
    "    print(f\"  ‚úì Acuracia (CV): {grid_search.best_score_:.4f}\\n\")\n",
    "\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6471c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Teste Final no Hold-Out - COMPLEXO vs SIMPLES\n",
      "============================================================\n",
      "Naive Bayes              : CV=0.7961 | Hold-Out=0.7924\n",
      "Logistic Regression      : CV=0.8238 | Hold-Out=0.8131\n",
      "SVM (LinearSVC)          : CV=0.8216 | Hold-Out=0.8127\n",
      "\n",
      "Melhor modelo (Hold-Out): Logistic Regression - 81.31%\n"
     ]
    }
   ],
   "source": [
    "# Teste Final - complexo_simples (com melhores params do Grid Search)\n",
    "print(\"\\nTeste Final no Hold-Out - COMPLEXO vs SIMPLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_results_cs = {}\n",
    "for name, pipeline in best_models_cs.items():\n",
    "    y_pred = pipeline.predict(X_test_cs)\n",
    "    acc = accuracy_score(y_test_cs, y_pred)\n",
    "    final_results_cs[name] = {'holdout_acc': acc, 'cv_mean': cv_results_cs[name]['mean']}\n",
    "    print(f\"{name:25s}: CV={cv_results_cs[name]['mean']:.4f} | Hold-Out={acc:.4f}\")\n",
    "\n",
    "best_final_cs = max(final_results_cs.items(), key=lambda x: x[1]['holdout_acc'])\n",
    "print(f\"\\nMelhor modelo (Hold-Out): {best_final_cs[0]} - {best_final_cs[1]['holdout_acc']*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1068aadf",
   "metadata": {},
   "source": [
    "# DATASET 3: LITERAL vs DIN√ÇMICO\n",
    "\n",
    "Classifica√ß√£o de textos entre estilo **literal** e **din√¢mico**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab861158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vetoriza√ß√£o conclu√≠da - train_literal_dinamico.csv\n",
      "   Treino: (31419, 4000) | Teste: (5545, 4000)\n"
     ]
    }
   ],
   "source": [
    "# Preparar dados - literal_dinamico\n",
    "X_train_ld = datasets[\"train_literal_dinamico.csv\"][\"X_train\"]\n",
    "X_test_ld = datasets[\"train_literal_dinamico.csv\"][\"X_test\"]\n",
    "y_train_ld = datasets[\"train_literal_dinamico.csv\"][\"y_train\"]\n",
    "y_test_ld = datasets[\"train_literal_dinamico.csv\"][\"y_test\"]\n",
    "\n",
    "print(f\"Dados carregados - train_literal_dinamico.csv\")\n",
    "print(f\"   Treino: {len(X_train_ld)} textos | Teste: {len(X_test_ld)} textos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1b6770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GRID SEARCH - LITERAL vs DIN√ÇMICO (10-FOLD CV)\n",
      "================================================================================\n",
      "\n",
      "Otimizando hiperparametros...\n",
      "\n",
      "[Naive Bayes] Executando Grid Search...\n",
      "  ‚úì Melhores params: {'alpha': 0.1}\n",
      "  ‚úì Acuracia (CV): 0.8161\n",
      "\n",
      "[Logistic Regression] Executando Grid Search...\n",
      "  ‚úì Melhores params: {'C': 1.0, 'class_weight': 'balanced', 'solver': 'liblinear'}\n",
      "  ‚úì Acuracia (CV): 0.8225\n",
      "\n",
      "[SVM (LinearSVC)] Executando Grid Search...\n",
      "  ‚úì Melhores params: {'C': 0.1, 'max_iter': 1000}\n",
      "  ‚úì Acuracia (CV): 0.8215\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"GRID SEARCH COM PIPELINE - LITERAL vs DIN√ÇMICO (10-FOLD CV)\")\n",
    "print(\"=\"*80)\n",
    "print(\"Otimizando TF-IDF + Modelos simultaneamente...\\n\")\n",
    "\n",
    "# Armazenar melhores pipelines\n",
    "best_models_ld = {}\n",
    "cv_results_ld = {}\n",
    "\n",
    "for name, config in param_grids.items():\n",
    "    print(f\"[{name}] Executando Grid Search...\")\n",
    "    print(f\"   Testando {len(config['params']['vectorizer__max_features']) * len(config['params']['vectorizer__ngram_range']) * len(config['params']['vectorizer__min_df']) * len(config['params']['vectorizer__max_df'])} combina√ß√µes de TF-IDF...\")\n",
    "    \n",
    "    # Grid Search com 10-fold CV\n",
    "    grid_search = GridSearchCV(\n",
    "        config['pipeline'],\n",
    "        config['params'],\n",
    "        cv=10,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train_ld, y_train_ld)\n",
    "    \n",
    "    # Armazenar resultados\n",
    "    best_models_ld[name] = grid_search.best_estimator_\n",
    "    \n",
    "    # Separar par√¢metros de TF-IDF e modelo\n",
    "    vectorizer_params = {k.replace('vectorizer__', ''): v \n",
    "                        for k, v in grid_search.best_params_.items() \n",
    "                        if k.startswith('vectorizer__')}\n",
    "    model_params = {k.replace('model__', ''): v \n",
    "                   for k, v in grid_search.best_params_.items() \n",
    "                   if k.startswith('model__')}\n",
    "    \n",
    "    cv_results_ld[name] = {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'vectorizer_params': vectorizer_params,\n",
    "        'model_params': model_params,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'mean': grid_search.best_score_,\n",
    "        'std': grid_search.cv_results_['std_test_score'][grid_search.best_index_]\n",
    "    }\n",
    "    \n",
    "    print(f\"  ‚úì Melhores params TF-IDF: {vectorizer_params}\")\n",
    "    print(f\"  ‚úì Melhores params Modelo: {model_params}\")\n",
    "    print(f\"  ‚úì Acuracia (CV): {grid_search.best_score_:.4f}\\n\")\n",
    "\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1629c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Teste Final no Hold-Out - LITERAL vs DIN√ÇMICO\n",
      "============================================================\n",
      "Naive Bayes              : CV=0.8161 | Hold-Out=0.8061\n",
      "Logistic Regression      : CV=0.8225 | Hold-Out=0.8227\n",
      "SVM (LinearSVC)          : CV=0.8215 | Hold-Out=0.8204\n",
      "\n",
      "Melhor modelo (Hold-Out): Logistic Regression - 82.27%\n"
     ]
    }
   ],
   "source": [
    "# Teste Final - literal_dinamico (com melhores params do Grid Search)\n",
    "print(\"\\nTeste Final no Hold-Out - LITERAL vs DIN√ÇMICO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_results_ld = {}\n",
    "for name, pipeline in best_models_ld.items():\n",
    "    y_pred = pipeline.predict(X_test_ld)\n",
    "    acc = accuracy_score(y_test_ld, y_pred)\n",
    "    final_results_ld[name] = {'holdout_acc': acc, 'cv_mean': cv_results_ld[name]['mean']}\n",
    "    print(f\"{name:25s}: CV={cv_results_ld[name]['mean']:.4f} | Hold-Out={acc:.4f}\")\n",
    "\n",
    "best_final_ld = max(final_results_ld.items(), key=lambda x: x[1]['holdout_acc'])\n",
    "print(f\"\\nMelhor modelo (Hold-Out): {best_final_ld[0]} - {best_final_ld[1]['holdout_acc']*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e685c0",
   "metadata": {},
   "source": [
    "# COMPARA√á√ÉO FINAL - TODOS OS DATASETS\n",
    "\n",
    "An√°lise comparativa do desempenho dos modelos nos 3 tipos de classifica√ß√£o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c23abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "COMPARA√á√ÉO FINAL - TODOS OS DATASETS\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "DATASET: ARCAICO vs MODERNO\n",
      "====================================================================================================\n",
      "\n",
      "Primeiro Lugar:\n",
      "   Acur√°cia CV:      0.8217 (82.17%)\n",
      "   Acur√°cia Hold-Out: 0.8227 (82.27%)\n",
      "   Melhores params:  {'C': 0.1, 'max_iter': 1000}\n",
      "\n",
      "Segundo Lugar:\n",
      "   Acur√°cia CV:      0.8222 (82.22%)\n",
      "   Acur√°cia Hold-Out: 0.8225 (82.25%)\n",
      "   Melhores params:  {'C': 1.0, 'class_weight': 'balanced', 'solver': 'lbfgs'}\n",
      "\n",
      "Terceiro Lugar:\n",
      "   Acur√°cia CV:      0.8167 (81.67%)\n",
      "   Acur√°cia Hold-Out: 0.8084 (80.84%)\n",
      "   Melhores params:  {'alpha': 0.1}\n",
      "\n",
      "====================================================================================================\n",
      "DATASET: COMPLEXO vs SIMPLES\n",
      "====================================================================================================\n",
      "\n",
      "Primeiro Lugar:\n",
      "   Acur√°cia CV:      0.8238 (82.38%)\n",
      "   Acur√°cia Hold-Out: 0.8131 (81.31%)\n",
      "   Melhores params:  {'C': 10.0, 'class_weight': None, 'solver': 'lbfgs'}\n",
      "\n",
      "Segundo Lugar:\n",
      "   Acur√°cia CV:      0.8216 (82.16%)\n",
      "   Acur√°cia Hold-Out: 0.8127 (81.27%)\n",
      "   Melhores params:  {'C': 1.0, 'max_iter': 1000}\n",
      "\n",
      "Terceiro Lugar:\n",
      "   Acur√°cia CV:      0.7961 (79.61%)\n",
      "   Acur√°cia Hold-Out: 0.7924 (79.24%)\n",
      "   Melhores params:  {'alpha': 0.1}\n",
      "\n",
      "====================================================================================================\n",
      "DATASET: LITERAL vs DIN√ÇMICO\n",
      "====================================================================================================\n",
      "\n",
      "Primeiro Lugar:\n",
      "   Acur√°cia CV:      0.8225 (82.25%)\n",
      "   Acur√°cia Hold-Out: 0.8227 (82.27%)\n",
      "   Melhores params:  {'C': 1.0, 'class_weight': 'balanced', 'solver': 'liblinear'}\n",
      "\n",
      "Segundo Lugar:\n",
      "   Acur√°cia CV:      0.8215 (82.15%)\n",
      "   Acur√°cia Hold-Out: 0.8204 (82.04%)\n",
      "   Melhores params:  {'C': 0.1, 'max_iter': 1000}\n",
      "\n",
      "Terceiro Lugar:\n",
      "   Acur√°cia CV:      0.8161 (81.61%)\n",
      "   Acur√°cia Hold-Out: 0.8061 (80.61%)\n",
      "   Melhores params:  {'alpha': 0.1}\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "RESUMO - MELHOR MODELO POR DATASET\n",
      "====================================================================================================\n",
      "\n",
      "ARCAICO vs MODERNO\n",
      "   Melhor Modelo: SVM (LinearSVC)\n",
      "   Acur√°cia: 82.27%\n",
      "   Par√¢metros: {'C': 0.1, 'max_iter': 1000}\n",
      "\n",
      "COMPLEXO vs SIMPLES\n",
      "   Melhor Modelo: Logistic Regression\n",
      "   Acur√°cia: 81.31%\n",
      "   Par√¢metros: {'C': 10.0, 'class_weight': None, 'solver': 'lbfgs'}\n",
      "\n",
      "LITERAL vs DIN√ÇMICO\n",
      "   Melhor Modelo: Logistic Regression\n",
      "   Acur√°cia: 82.27%\n",
      "   Par√¢metros: {'C': 1.0, 'class_weight': 'balanced', 'solver': 'liblinear'}\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*100)\n",
    "print(\"COMPARA√á√ÉO FINAL - TODOS OS DATASETS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Organizar resultados com par√¢metros\n",
    "datasets_comparison = {\n",
    "    'ARCAICO vs MODERNO': {\n",
    "        'results': final_results,\n",
    "        'cv_results': cv_results\n",
    "    },\n",
    "    'COMPLEXO vs SIMPLES': {\n",
    "        'results': final_results_cs,\n",
    "        'cv_results': cv_results_cs\n",
    "    },\n",
    "    'LITERAL vs DIN√ÇMICO': {\n",
    "        'results': final_results_ld,\n",
    "        'cv_results': cv_results_ld\n",
    "    }\n",
    "}\n",
    "\n",
    "# Mostrar resultados por dataset\n",
    "for dataset_name, data in datasets_comparison.items():\n",
    "    results = data['results']\n",
    "    cv_res = data['cv_results']\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"DATASET: {dataset_name}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    # Ordenar por Hold-Out\n",
    "    sorted_results = sorted(results.items(), key=lambda x: x[1]['holdout_acc'], reverse=True)\n",
    "    \n",
    "    for i, (model_name, metrics) in enumerate(sorted_results, 1):\n",
    "        emoji = \"ü•á\" if i == 1 else \"ü•à\" if i == 2 else \"ü•â\"\n",
    "        print(f\"\\n{emoji} {model_name}\")\n",
    "        print(f\"   Acur√°cia CV:       {metrics['cv_mean']:.4f} ({metrics['cv_mean']*100:.2f}%)\")\n",
    "        print(f\"   Acur√°cia Hold-Out: {metrics['holdout_acc']:.4f} ({metrics['holdout_acc']*100:.2f}%)\")\n",
    "        print(f\"   Params TF-IDF:     {cv_res[model_name]['vectorizer_params']}\")\n",
    "        print(f\"   Params Modelo:     {cv_res[model_name]['model_params']}\")\n",
    "\n",
    "# Resumo final - Melhor modelo por dataset\n",
    "print(f\"\\n\\n{'='*100}\")\n",
    "print(\"RESUMO - MELHOR MODELO POR DATASET\")\n",
    "print(f\"{'='*100}\\n\")\n",
    "\n",
    "for dataset_name, data in datasets_comparison.items():\n",
    "    results = data['results']\n",
    "    cv_res = data['cv_results']\n",
    "    \n",
    "    best = max(results.items(), key=lambda x: x[1]['holdout_acc'])\n",
    "    best_name = best[0]\n",
    "    best_metrics = best[1]\n",
    "    \n",
    "    print(f\"üèÜ {dataset_name}\")\n",
    "    print(f\"   Melhor Modelo:     {best_name}\")\n",
    "    print(f\"   Acur√°cia Hold-Out: {best_metrics['holdout_acc']*100:.2f}%\")\n",
    "    print(f\"   Params TF-IDF:     {cv_res[best_name]['vectorizer_params']}\")\n",
    "    print(f\"   Params Modelo:     {cv_res[best_name]['model_params']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
