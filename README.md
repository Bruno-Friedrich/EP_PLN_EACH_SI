# ğŸ”¤ ClassificaÃ§Ã£o de Estilos Textuais com PLN

RepositÃ³rio desenvolvido para o **ExercÃ­cio Programa (EP)** da disciplina de **Processamento de LÃ­ngua Natural (PLN)** - EACH USP.

Este projeto implementa um pipeline completo de Machine Learning para classificaÃ§Ã£o de textos em trÃªs diferentes pares de estilos literÃ¡rios: **Arcaico vs Moderno**, **Complexo vs Simples**, e **Literal vs DinÃ¢mico**.

---

## **SumÃ¡rio**

- [VisÃ£o Geral](#-visÃ£o-geral)
- [Datasets](#-datasets)
- [Metodologia](#-metodologia)
- [Pipeline de Processamento](#-pipeline-de-processamento)
- [Modelos Implementados](#-modelos-implementados)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Como Executar](#-como-executar)

---

## **VisÃ£o Geral**

O projeto visa desenvolver modelos de classificaÃ§Ã£o de textos capazes de distinguir diferentes estilos literÃ¡rios. Utilizamos tÃ©cnicas de **Processamento de LÃ­ngua Natural (PLN)** e **Machine Learning** para treinar, validar e testar modelos em trÃªs tarefas distintas de classificaÃ§Ã£o binÃ¡ria.

**Principais caracterÃ­sticas:**

- Pipeline completo (prÃ©-processamento â†’ vetorizaÃ§Ã£o â†’ treinamento â†’ validaÃ§Ã£o â†’ teste)
- Grid Search com otimizaÃ§Ã£o de hiperparÃ¢metros (TF-IDF + Modelos)
- ValidaÃ§Ã£o Cruzada (10-fold CV) para avaliaÃ§Ã£o robusta
- Hold-out set (15%) para teste final imparcial
- ComparaÃ§Ã£o sistemÃ¡tica entre 3 modelos e 3 datasets

---

## **Datasets**

O projeto trabalha com trÃªs conjuntos de dados balanceados:

| Dataset                        | Classes            | Total de Linhas | ProporÃ§Ã£o | Balanceamento            |
| ------------------------------ | ------------------ | --------------- | --------- | ------------------------ |
| **train_arcaico_moderno.csv**  | arcaico / moderno  | 36,884          | 50% / 50% | Perfeitamente balanceado |
| **train_complexo_simples.csv** | complexo / simples | 33,422          | 50% / 50% | Perfeitamente balanceado |
| **train_literal_dinamico.csv** | literal / dinÃ¢mico | 36,964          | 50% / 50% | Perfeitamente balanceado |

**Estrutura dos CSVs:**

```
text;style
"Texto de exemplo aqui...";arcaico
"Outro texto exemplo...";moderno
```

**AnÃ¡lise de qualidade:**

- Todos os datasets sÃ£o balanceados (razÃ£o 1.00x)
- Nenhum valor nulo encontrado (exceto 1 em train_complexo_simples.csv)
- Textos em portuguÃªs (variados tamanhos e complexidades)

---

## **Metodologia**

### **1. PrÃ©-Processamento**

Aplicamos tÃ©cnicas minimalistas de prÃ©-processamento para preservar caracterÃ­sticas estilÃ­sticas importantes:

```python
preprocess_params = {
    "lowercase": True,                  # ConversÃ£o para minÃºsculas
    "normalize_unicode": False,         # MantÃ©m caracteres especiais
    "remove_extra_whitespace": True,    # Remove espaÃ§os extras
    "remove_punct": False,              # MantÃ©m pontuaÃ§Ã£o (importante para estilo)
}
```

### **2. SeparaÃ§Ã£o Treino/Teste**

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.15,      # 85% treino / 15% teste
    stratify=y,          # MantÃ©m proporÃ§Ã£o das classes
    random_state=10      # Reprodutibilidade
)
```

- **Stratified split:** MantÃ©m proporÃ§Ã£o 50/50 em treino e teste
- **Hold-out set:** 15% dos dados nunca sÃ£o vistos durante treino/validaÃ§Ã£o
- **Reprodutibilidade:** `random_state=10` garante resultados consistentes

### **3. VetorizaÃ§Ã£o (TF-IDF)**

Usamos **TF-IDF (Term Frequency-Inverse Document Frequency)** integrado ao pipeline via `GridSearchCV`:

**HiperparÃ¢metros otimizados:**

```python
'vectorizer__max_features': [3000, 5000, 10000],  # NÃºmero de features
'vectorizer__ngram_range': [(1, 1), (1, 2)],      # Unigrams e Bigrams
'vectorizer__min_df': [2, 5],                     # FrequÃªncia mÃ­nima
'vectorizer__max_df': [0.9, 0.95],                # FrequÃªncia mÃ¡xima (remove stop words)
```

### **4. Pipeline de Treinamento**

Utilizamos `sklearn.pipeline.Pipeline` para integrar vetorizaÃ§Ã£o e modelo:

```python
Pipeline([
    ('vectorizer', TfidfVectorizer()),  # Etapa 1: Texto â†’ Vetores
    ('model', MultinomialNB())          # Etapa 2: Vetores â†’ ClassificaÃ§Ã£o
])
```

**ValidaÃ§Ã£o Cruzada (10-fold CV)**

```python
GridSearchCV(
    pipeline,
    param_grid,
    cv=10,              # 10 folds
    scoring='accuracy',
    n_jobs=-1           # ParalelizaÃ§Ã£o
)
```

**Como funciona:**

```
Dados de Treino (85%)
    â†“
Dividir em 10 partes (folds)
    â†“
Para cada combinaÃ§Ã£o de hiperparÃ¢metros:
    Fold 1: Treina em 9/10, valida em 1/10
    Fold 2: Treina em 9/10, valida em 1/10
    ...
    Fold 10: Treina em 9/10, valida em 1/10
    â†“
MÃ©dia das 10 acurÃ¡cias = Score do CV
    â†“
Escolhe a melhor combinaÃ§Ã£o
```

**Vantagens:**

- Mais robusto que train/val split simples
- Detecta overfitting

### **6. Teste Final (Hold-out Set)**

- Dados nunca vistos durante treino/validaÃ§Ã£o

```python
best_pipeline = grid_search.best_estimator_
y_pred = best_pipeline.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
```

---

## **Modelos Implementados**

### **1. Naive Bayes (MultinomialNB)**

```python
MultinomialNB(alpha=...)
```

**HiperparÃ¢metros otimizados:**

- `alpha`: [0.1, 0.5, 1.0, 2.0] (suavizaÃ§Ã£o de Laplace)

### **2. Logistic Regression**

```python
LogisticRegression(C=..., solver=..., class_weight=...)
```

**HiperparÃ¢metros otimizados:**

- `C`: [0.1, 1.0, 10.0] (regularizaÃ§Ã£o inversa)
- `solver`: ['lbfgs', 'liblinear']
- `class_weight`: ['balanced', None]

### **3. SVM (LinearSVC)**

```python
LinearSVC(C=..., max_iter=..., dual=False)
```

**HiperparÃ¢metros otimizados:**

- `C`: [0.1, 1.0, 10.0] (regularizaÃ§Ã£o)
- `max_iter`: [1000, 2000]

## **Estrutura do Projeto**

```
EP_PLN_EACH_SI/
â”‚
â”œâ”€â”€ treino/                                 # Datasets de treinamento
â”‚   â”œâ”€â”€ train_arcaico_moderno.csv          # Dataset 1
â”‚   â”œâ”€â”€ train_complexo_simples.csv         # Dataset 2
â”‚   â””â”€â”€ train_literal_dinamico.csv         # Dataset 3
â”‚
â”œâ”€â”€ EP.ipynb                                # Notebook principal
â”œâ”€â”€ README.md                               # Este arquivo
```

---

## **Como Executar**

### **PrÃ©-requisitos**

- Python 3.8+
- Jupyter Notebook ou JupyterLab
- Bibliotecas listadas em [Requisitos](#-requisitos)

### **Passo a Passo**

1. **Clone o repositÃ³rio:**

```bash
git clone https://github.com/seu-usuario/EP_PLN_EACH_SI.git
cd EP_PLN_EACH_SI
```

2. **Instale as dependÃªncias:**

```bash
pip install -r requirements.txt
```

3. **Abra o Jupyter Notebook:**

```bash
jupyter notebook EP.ipynb
```

4. **Execute todas as cÃ©lulas:**

- No menu: `Cell` â†’ `Run All`
- Ou: `Ctrl+Shift+Enter` em cada cÃ©lula

5. **Visualize os resultados:**

- AnÃ¡lise de balanceamento dos datasets
- Resultados do Grid Search (CV)
- Teste final no hold-out set
- ComparaÃ§Ã£o entre datasets

## **Requisitos**

### **Bibliotecas Python**

```python
# ManipulaÃ§Ã£o de dados
pandas>=1.3.0
numpy>=1.21.0

# Machine Learning
scikit-learn>=1.0.0

# Jupyter
jupyter>=1.0.0
notebook>=6.4.0
```

### **Instalar dependÃªncias:**

```bash
pip install pandas numpy scikit-learn jupyter notebook
```

---

## **Autores**

- BrunÃ£o Friedrich
- Lucas Ferracin
- Pablo AssunÃ§Ã£o
- Yannis Pontuschka
